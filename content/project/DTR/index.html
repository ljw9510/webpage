---
title: "Review of 'Q- and A-learning Methods for Estimating Optimal Dynamic Treatment Regimes'"
subtitle: Phillip J. Schulte, Anastasios A. Tsiatis, Eric B. Laber, and Marie Davidian
author: "Joowon Lee"
date: "2022-10-24"
categories: ["Causal Inference"]
tags: ["Causal Inference", "Dynamic Treatment Regime"]
excerpt: Review of the paper "Q- and A-learning Methods for Estimating Optimal Dynamic Treatment Regimes" written by P. J. Schulte, et al., (2014).
links:
- icon: door-open
  icon_pack: fas
  name: paper
  url: https://pubmed.ncbi.nlm.nih.gov/25620840/
---



<hr />
<div id="list" class="section level3">
<h3>List</h3>
<p><a href="#overview">1. Overview</a></p>
<p><a href="#identification">2. Identification</a></p>
<p><a href="#optimal_treatment_regime">3. Optimal Treatment Regimes</a></p>
<p><a href="#estimation_dtr">4. Estimation of Optimal Treatment Regimes</a></p>
<p><a href="#estimation">5. Estimation of Potential Outcome</a></p>
<p><a href="#simulation">6. Simlation Studies</a></p>
<p><a href="#sensitivity">7. Sensitivity Analysis</a></p>
<p><a href="#summary">8. Summary</a></p>
<hr />
</div>
<div id="overview" class="section level3">
<h3>Overview</h3>
<p>In this project, we will review a paper <em>Q- and A-learning Methods for Estimating Optimal Dynamic Treatment Regimes</em> written by Phillip J. Schulte et al., (2014) <a href="https://pubmed.ncbi.nlm.nih.gov/25620840/">[paper]</a>, focusing on Q-learning methods.</p>
<p>In clinical practice, clinicians make a series of decisions based on individual patient’s baseline and evolving characteristics. In this paper, we wanted to make optimal sequential treatment decisions to achieve the ‘best’ outcome for an individual patient. The list of sequential decision rules is formalized as a dynamic treatment regime. Throughout this paper, we investigate two main methods, Q-learning and A-learning, to estimate the optimal dynamic treatment regime based on data from a clinical trial or observational study.</p>
<p>Let us first introduce the following notations:</p>
<blockquote>
<ul>
<li><span class="math inline">\(k\)</span> : stages or pre-specified ordered decision points <span class="math inline">\(k = 1, \cdots, K\)</span>,</li>
<li><span class="math inline">\(\Omega\)</span> : a superpopulation of patients with a patient <span class="math inline">\(\omega \in \Omega\)</span>,</li>
<li><span class="math inline">\(Y\)</span> : a final outcome of interest (assuming that large values are preferred),</li>
<li><span class="math inline">\(X_{k}\)</span> : covariate information immediately prior to decision <span class="math inline">\(k\)</span> with value <span class="math inline">\(x_{k} \in \mathcal{X}_{k}\)</span>,</li>
<li><span class="math inline">\(A_{k}\)</span> : treatment at stage <span class="math inline">\(k\)</span> with value <span class="math inline">\(a_{k} \in \mathcal{A}_{k}\)</span> (a finite set possible options)</li>
<li><span class="math inline">\(\overline{a_{k}} = (a_{1}, \cdots, a_{k})\)</span> : a possible treatment history through decision <span class="math inline">\(k\)</span> taking values in <span class="math inline">\(\overline{\mathcal{A}_{k}} = \mathcal{A}_{1} \times \cdots \mathcal{A}_{k}\)</span>.</li>
</ul>
</blockquote>
<blockquote>
<p>Then we define the <strong>potential outcomes</strong>
<span class="math display">\[\begin{align*}
W^{*} &amp;= \left\{ X^{*}_{2}(a_{1}), X^{*}_{3}\big(\overline{a_{2}}\big), \cdots, X^{*}_{K}\big(\overline{a_{k-1}}\big), Y^{*}\big(\overline{a_{k}}\big) \,\, \text{ for all } \, \overline{a_{k}} \in \overline{\mathcal{A}_{k}} \right\}
\end{align*}\]</span></p>
</blockquote>
<p>Here, <span class="math inline">\(X^{*}_{K}\big(\overline{a_{k-1}}\big)(\omega)\)</span> denotes the value of covariate information that would arise between decisions <span class="math inline">\(k-1\)</span> and <span class="math inline">\(k\)</span> for a patient <span class="math inline">\(\omega \in \Omega\)</span> who have received treatment history <span class="math inline">\(\overline{a_{k-1}}\)</span>, taking value <span class="math inline">\(x_{k}\)</span> in a set <span class="math inline">\(\mathcal{X}_{k}\)</span>. Similarly, <span class="math inline">\(Y^{*}\big(\overline{a_{k}}\big)\)</span> is the hypothetical outcome that would result for a patient <span class="math inline">\(\omega\)</span> who have received the full set of <span class="math inline">\(K\)</span> treatment in <span class="math inline">\(\overline{a_{k}}\)</span>. For simplicity, we write <span class="math inline">\(\overline{X}^{*}_{\underline{k}}\big(\overline{a_{k-1}}\big)=\{X_{1}, X^{*}_{2}(a_{1}), \cdots, X^{*}_{k}\big(\overline{a_{k-1}}\big)\}, k = 1, \cdots, K\)</span>.</p>
<hr />
</div>
<div id="dynamic-treatment-regime" class="section level3">
<h3>Dynamic Treatment Regime</h3>
<p>A dynamic treatment regime <span class="math inline">\(\mathbf{d} = (d_{1}, \cdots, d_{K})\)</span> is a set of rules that forms an algorithm to treat individual patient over time (it is called ‘<em>dynamic</em>’ because treatment is determined based on a patient’s previous history). For example, at the <span class="math inline">\(k\)</span>th stage,</p>
<ul>
<li>the <span class="math inline">\(k\)</span>th rule <span class="math inline">\(d_{k}\)</span> takes
<ul>
<li>input : <span class="math inline">\(\overline{x_{k}}, \overline{a_{k-1}}\)</span> (patient’s realized covariate, and treatment history up to <span class="math inline">\(k-1\)</span>th decision),</li>
<li>output : <span class="math inline">\(a_{k} \in \Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}}) \subset \mathcal{A}_{k}\)</span> where <span class="math inline">\(\Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}})\)</span> is a pre-specified set of possible traetment options for a patient with (<span class="math inline">\(\overline{x_{k}}, \overline{a_{k-1}}\)</span>).</li>
</ul></li>
</ul>
<p>Since <span class="math inline">\(d_{k}\)</span> need only map a subset of <span class="math inline">\(\overline{\mathcal{X}_{k}} \times \overline{\mathcal{A}_{k-1}}\)</span>, namely <span class="math inline">\(\Gamma_{k}\)</span>, to <span class="math inline">\(\mathcal{A}_{k}\)</span>, let us define the subset <strong>recursively</strong> as</p>
<p><span class="math display">\[\begin{align*}
\Gamma_{k} &amp;= \{ (\overline{x_{k}}, \overline{a_{k-1}}) \in \overline{\mathcal{X}_{k}} \times \overline{\mathcal{A}_{k-1}} \,\, \text{ satisfying } \\
&amp; \quad \quad \text{(i) } \, a_{j} \in \Psi_{j}\big( \overline{x_{j}}, \overline{a_{j-1}} \big), \,\, j = 1, \cdots, k-1, \\
&amp; \quad \quad \text{(ii) } \, \mathbb{P}(\overline{X_{k}}\big(\overline{a_{k-1}} \big)=\overline{x_{k}})&gt;0\},
\end{align*}\]</span></p>
<p><span class="math inline">\(k=1, \cdots, K\)</span>, determined by <span class="math inline">\(\Psi=(\Psi_{1}, \cdots, \Psi_{K})\)</span>. Define the class <span class="math inline">\(\mathcal{D}\)</span> of dynamic treatment regimes to be the set of all <span class="math inline">\(\mathbf{d}=(d_{1}, \cdots. d_{k})\)</span> where <span class="math inline">\(d_{k}: \Gamma_{k} \rightarrow \mathcal{A}_{k}, k=1, \cdots, K\)</span>.</p>
<blockquote>
<p>Then, for any <span class="math inline">\(\mathbf{d} \in \mathcal{D}\)</span>, define the <strong>potential outcomes associated with <span class="math inline">\(\mathbf{d}\)</span></strong> as
<span class="math display">\[\begin{align*}
\left\{ X^{*}_{2}(d_{1}),  \cdots, X^{*}_{k}\big(\overline{d_{k-1}}\big), \cdots,  X^{*}_{K}\big(\overline{d_{K-1}}\big), Y^{*}\big(\mathbf{d}\big) \,\, \right\}
\end{align*}\]</span></p>
</blockquote>
<p>Then how can we find an optimal regime (the ‘best’ treatment for a patient) with these definitions?</p>
<p>The expected outcome in the population if all patients who have a baseline covariate <span class="math inline">\(X_{1} = x_{1}\)</span> were to follow regime <span class="math inline">\(\mathbf{d}\)</span> is <span class="math inline">\(\mathbb{E}[Y^{*}\big(\mathbf{d}\big)\ | X_{1} = x_{1}]\)</span>. Then an optimal regime, <span class="math inline">\(\mathbf{d}^{opt} \in \mathcal{D}\)</span>, should satisfy</p>
<p><span class="math display">\[\begin{align*}
&amp; \mathbb{E}[Y^{*}\big(\mathbf{d}\big)\ | X_{1} = x_{1}] \quad \le \quad \mathbb{E}[Y^{*}\big(\mathbf{d}^{opt}\big)\ | X_{1} = x_{1}], \,\, \text{ for all } \mathbf{d} \in \mathcal{D} \text{ and all } x_{1} \in \mathcal{X}_{1} \\
\Rightarrow \,\, &amp; \mathbb{E}[Y^{*}\big(\mathbf{d}\big)] \qquad \qquad \quad \, \le \quad \mathbb{E}[Y^{*}\big(\mathbf{d}^{opt}\big)], \qquad \quad \quad \,\, \text{ for all } \mathbf{d} \in \mathcal{D}
\end{align*}\]</span></p>
<p>the first inequality implies the second one since it is true for any fixed <span class="math inline">\(x_{1} \in \mathcal{X}_{1}\)</span>.</p>
<hr />
</div>
<div id="Model_Setup_and_Assumptions" class="section level3">
<h3>Model Setup and Assumptions</h3>
<p>The problem is that potential outcomes for an individual patient for all <span class="math inline">\(\mathbf{d} \in \mathcal{D}\)</span> may not be observed. Therefore, the goal of dynamic treatment regime is to estimate <span class="math inline">\(\mathbf{d}^{opt}\)</span> based on data.</p>
<p>Consider a study with a random sample of <span class="math inline">\(n\)</span> patients in <span class="math inline">\(\Omega\)</span>. Assume independent and identically distributed time-ordered random variables <span class="math inline">\((X_{1i}, A_{1i}, \cdots, X_{Ki}, A_{Ki}, Y_{i}), i = 1, \cdots, n\)</span> on <span class="math inline">\(\Omega\)</span>. Use causal framework to estimate an optimal regime from the observed data under the following assumptions:</p>
<ul>
<li>Consistency assumption : <span class="math inline">\(X_{k} = X^{*}_{k}\big(\overline{A_{k-1}}\big), k=2, \cdots, K\)</span> and <span class="math inline">\(Y=Y^{*}\big(\overline{A_{k}}\big)\)</span>,</li>
<li>Stable unit treatment value assumption (well-defined) : a patient’s covariates and outcome are not affected by treatment assignment and other patients,</li>
<li>Sequential Ignorability : <span class="math inline">\(A_{k} \perp W^{*} | \{\overline{X_{k}}, \overline{A_{k-1}} \}, k=1, \cdots, K\)</span>.</li>
</ul>
<hr />
</div>
<div id="identification" class="section level3">
<h3>Identification</h3>
<p>In this section, we are interested in identifying the expected potential outcome <span class="math inline">\(\mathbb{E}[Y^{*}(\overline{a_{K}})]\)</span> which may or may not be observable based on statistical quantity.</p>
<p>We first consider a fixed treatment <span class="math inline">\((a_{1}, a_{2}) \in \{0, 1\}^{2}\)</span> with the two time points <span class="math inline">\((k = 2)\)</span>. We have time-ordered variables <span class="math inline">\((X_{1}, A_{1}, X_{2}, A_{2}, Y)\)</span>, where the dependency between them can be described as the following dynamic acyclic graph (DAG):</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dag"></span>
<img src="figures/dag.png" alt="Dynamic acyclic graph for k = 2" width="50%" />
<p class="caption">
Figure 1: Dynamic acyclic graph for k = 2
</p>
</div>
<p>From the following lemma below, we show that the expected potential outcome <span class="math inline">\(\mathbb{E}[Y^{*}(\overline{a_{2}})]=\mathbb{E}[Y^{*}(a_{1}, a_{2})]\)</span> of treatment <span class="math inline">\((a_{1}, a_{2})\)</span> can be identified as a statistical estimand, a function of conditional expectation.</p>
<p><br />
</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-1" class="lemma"><strong>Lemma 1  </strong></span><em>Fix a treatment <span class="math inline">\((a_{1},a_{2})\in \{0,1\}^{2}\)</span>. Under the assumptions of consistency, SUTVA, and sequential ignorability mentioned in the section <a href="#Model_Setup_and_Assumptions">Model setup and assumptions</a>, we have</em>
<span class="math display">\[\begin{align*}
&amp;\mathbb{E}[Y^{*}(a_1, a_2)] \\
&amp; \quad = \mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X_{2}} \bigg[ \mathbb{E}_{Y}[Y | X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2}] \bigg| X_{1}, A_{1} = a_{1} \bigg] \bigg] \\
&amp; \quad = \int_{x_{1}} \int_{x_{2}} \mathbb{E}_{Y}[Y | X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2}] \,\, \mathbb{P}\left(X_{2}=x_{2}|X_{1}=x_{1}, A_{1} = a_{1} \right) \mathbb{P}\left(X_{1}=x_{1}\right)dx_{2}dx_{1}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span><span class="math inline">\({}\)</span>
Here, let us denote <span class="math inline">\(X^{*}_{2} := X^{*}_{2}(a_{1})\)</span> and <span class="math inline">\(Y^{*} := Y^{*}(a_1, a_2)\)</span>, which we will be using when these random variables are in subscripts for simplicity. Then
<span class="math display">\[\begin{align*}
&amp;\mathbb{E}[Y^{*}(a_1, a_2)] \\
&amp;\quad =\mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X^{*}_{2},Y^{*}}[Y^{*}(a_1, a_2) | X_{1}]\bigg] \\
&amp;\quad \overset{(a)}{=}\mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X^{*}_{2},Y^{*}}[Y^{*}(a_1, a_2) | X_{1}, A_{1} = a_{1}]\bigg] \\
&amp;\quad \overset{(b)}{=}\mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X^{*}_{2}} \bigg[ \mathbb{E}_{Y^{*}}[Y^{*}(a_1, a_2) | X_{1}, A_{1} = a_{1}, X^{*}_{2}(a_{1})] \bigg| X_{1}, A_{1} = a_{1}\bigg] \bigg] \\
&amp;\quad \overset{(c)}{=}\mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X^{*}_{2}} \bigg[ \mathbb{E}_{Y^{*}}[Y^{*}(a_1, a_2) | X_{1}, A_{1} = a_{1}, X^{*}_{2}(a_{1}), A_{2} = a_{2}] \bigg| X_{1}, A_{1} = a_{1}\bigg] \bigg]  \\
&amp;\quad \overset{(d)}{=}\mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X_{2}} \bigg[ \mathbb{E}_{Y}[Y| X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2}] \bigg| X_{1}, A_{1} = a_{1}\bigg] \bigg] \\
&amp;\quad =  \int_{x_{1}} \int_{x_{2}} \mathbb{E}[Y | X_{1} = x_{1}, A_{1} = a_{1}, X_{2} = x_{2}, A_{2} = a_{2}] \mathbb{P}\left(X_{2} = x_{2} | X_{1} = x_{1}, A_{1} = a_{1}\right) \mathbb{P}(X_{1} = x_{1}) dx_{2} dx_{1}, \\
\end{align*}\]</span>
where (a) and (c) use sequential ignorability, (b) uses iterated expectation, and (d) use consistency.
<span class="math display">\[\begin{align*}
\hspace{15cm} \square
\end{align*}\]</span></p>
</div>
<p>Now consider the general case when we have <span class="math inline">\(K\)</span> time points. First define the following conditional expectation as <span class="math inline">\(\mu_{\overline{a_{K}}} (\overline{x_{K}})\)</span> for simplicity and introduce the lemma for identification with <span class="math inline">\(K\)</span> time points.</p>
<p><span class="math display">\[\begin{align*}
\mu_{\overline{a_{K}}} (\overline{x_{K}}) := \mathbb{E}[Y | \overline{X_{K}} = \overline{x_{K}}, \overline{A_{K}}= \overline{a_{K}}].
\end{align*}\]</span></p>
<p>Now consider the general case when we have <span class="math inline">\(K\)</span> time points. We have time-varying variables <span class="math inline">\((X_{1}, A_{1}, \cdots, X_{K}, A_{K}, Y)\)</span>, assuming all dependencies between variables with proper temporal orders as shown in Figure <a href="#fig:dag">1</a>. Then we introduce the lemma for identification with <span class="math inline">\(K\)</span> time points.</p>
<p><br />
</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-3" class="lemma"><strong>Lemma 2  </strong></span><em>Fix a treatment <span class="math inline">\(\overline{a_{K}}=(a_{1},\cdots,a_{K})\in \{0,1\}^{K}\)</span>. Under the assumptions of consistency, SUTVA, and sequential ignorability, we have</em>
<span class="math display">\[\begin{align*}
&amp;\mathbb{E}[Y^{*}(\overline{a_{K}})] \\
&amp;\quad = \mathbb{E}_{X_{1}} \bigg[ \mathbb{E}_{X_{2}} \bigg[ \cdots
\bigg[ \mathbb{E}_{X_{K}}\left[ \mathbb{E}\left[Y \bigg| \begin{matrix} \overline{X_{K}} \\ \overline{A_{K}} = \overline{a_{K}} \end{matrix}\right]
\bigg| \begin{matrix} \overline{X_{K-1}} \\ \overline{A_{k-1}} = \overline{a_{k-1}} \end{matrix} \right]  
\bigg| \begin{matrix} \overline{X_{K-2}} \\ \overline{A_{k-2}} = \overline{a_{k-2}} \end{matrix} \bigg] \cdots
\bigg| \begin{matrix} X_{1} \\ A_{1} = a_{1} \end{matrix}\bigg] \bigg]
\end{align*}\]</span></p>
</div>
<details>
<summary>
Click for proof
</summary>
<div class="proof">
<p><span id="unlabeled-div-4" class="proof"><em>Proof</em>. </span><span class="math inline">\({}\)</span></p>
<p>The idea of the proof is to use induction on the number of unobserved treatments. Let us define the following quantities:
<span class="math display">\[\begin{align*}
\mathcal{F}_{k} &amp;: \sigma \text{-algebra generated by information up to } k , \\
\overline{Z_{[k+1,K]}} &amp;= (Z_{k+1}, Z_{k+2}, \cdots, Z_{K}).
\end{align*}\]</span>
We prove the following stronger claim:</p>
<p>For <span class="math inline">\(k \in \{0, 1, \cdots, K \}\)</span>,
<span class="math display">\[\begin{align*}
&amp;\mathbb{E}\left[ Y^{*}(\overline{A_{k}}, \overline{a_{[k+1,K]}}) \bigg|\mathcal{F}_{k}\right]
= \mathbb{E}_{X_{k+1}}\left[ \mathbb{E}_{X_{k+2}}
\left[ \cdots \left[ \mathbb{E}\left[Y \bigg| \begin{matrix} \overline{X_{[k+1, K]}} \\ \overline{A_{[k+1, K]}} = \overline{a_{[k+1,T]}} \\ \mathcal{F}_{k} \end{matrix}\right] \bigg| \right] \cdots \right]
\bigg| \begin{matrix} \overline{X_{k+1}} \\ \overline{A_{k+1}} = \overline{a_{k+1}} \\ \mathcal{F}_{k} \end{matrix}
\right]
\end{align*}\]</span>
Then the statement follows by taking <span class="math inline">\(k=0\)</span>. We use induction on <span class="math inline">\(K-k=\)</span> the number of unobserved treatment.</p>
<p>First, Let <span class="math inline">\(k = K\)</span>. Since we have all information up to K and there is no counterfactual outcome,
<span class="math display">\[\begin{align*}
&amp; \mathbb{E}[Y^{*}(A_{1}, \cdots, A_{K})|\mathcal{F}_{K}]  = \mathbb{E}[Y|\overline{X_{K}}, \overline{A_{K}}, \mathcal{F}_{K}]. \\
\end{align*}\]</span></p>
<p>Next, assume induction hypothesis for <span class="math inline">\(k\)</span> holds. We wish to show induction hypothesis holds for <span class="math inline">\(k-1\)</span>.
<span class="math display">\[\begin{align*}
&amp; \mathbb{E}[Y^{*}(A_{1}, \cdots, A_{k-1}, a_{k}, \cdots, a_{K}) | \mathcal{F}_{k-1}] \\
&amp; \quad \overset{(a)}{=} \mathbb{E}_{X_{k}} \left[ \mathbb{E} \left[ Y^{*}(A_{1}, \cdots, A_{k-1}, a_{k}, \cdots, a_{K}) \bigg| X_{k}, \mathcal{F}_{k-1} \right] \right] \\
&amp; \quad \overset{(b)}{=} \mathbb{E}_{X_{k}} \left[ \mathbb{E} \left[ Y^{*}(A_{1}, \cdots, A_{k-1}, a_{k}, \cdots, a_{K}) \bigg| X_{k}, \overline{A_{k}} = \overline{a_{k}}, \mathcal{F}_{k-1} \right] \right] \\
&amp; \quad = \mathbb{E}_{X_{k}} \left[ \mathbb{E} \left[ Y^{*}(A_{1}, \cdots, A_{k-1}, A_{k}, \cdots, a_{K}) \bigg| X_{k}, \overline{A_{k}} = \overline{a_{k}}, \mathcal{F}_{k-1} \right] \right] \\
&amp; \quad \overset{(c)}{=} \mathbb{E}_{X_{k}} \left[ \mathbb{E} \left[ Y^{*}(A_{1}, \cdots, A_{k-1}, A_{k}, \cdots, a_{K}) \bigg| \mathcal{F}_{k} \right] \right] \\
&amp; \quad = \mathbb{E}_{X_{k}} \left[ \mathbb{E} \left[ Y^{*}(A_{1}, \cdots, A_{k}, a_{k+1}, \cdots, a_{K}) \bigg|  \mathcal{F}_{k} \right] \right] \\
&amp; \quad \overset{(d)}{=} \mathbb{E}_{X_{k}} \left[ \mathbb{E}_{X_{k+1}}\left[ \mathbb{E}_{X_{k+2}}
\left[ \cdots \left[ \mathbb{E}\left[Y \bigg| \begin{matrix} \overline{X_{[k+1, K]}} \\ \overline{A_{[k+1, K]}} = \overline{a_{[k+1,T]}} \\ \mathcal{F}_{k} \end{matrix}\right] \bigg| \right] \cdots \right]
\bigg| \begin{matrix} \overline{X_{k+1}} \\ \overline{A_{k+1}} = \overline{a_{k+1}} \\ \mathcal{F}_{k} \end{matrix}
\right] \right]
\end{align*}\]</span>
where (a) uses iterated expectation, (b) uses sequential ignorability, (c) uses no unmeasured confounder assumption in SUTVA, and (d) is from the assumed induction hypothesis. Since it holds for <span class="math inline">\(k-1\)</span>, we are done.
<span class="math display">\[\begin{align*}
\hspace{12.5cm} \square
\end{align*}\]</span></p>
</div>
</details>
<hr />
</div>
<div id="optimal_treatment_regime" class="section level3">
<h3>Optimal Treatment Regimes</h3>
<p>Q- and A-learning are two approaches to estimate <span class="math inline">\(d^{opt}\)</span> satisfying <span class="math inline">\(\mathbb{E}[Y^{*}\big(\mathbf{d}\big)] \le \mathbb{E}[Y^{*}\big(\mathbf{d}^{opt}\big)], \text{ for all } \mathbf{d} \in \mathcal{D}\)</span> which involve recursive algorithms. In this posting, we will focus on Q-learning method.</p>
<p>In this section, we demonstrate the formulation of <span class="math inline">\(d^{opt}\)</span> in terms of the potential outcomes and then show how <span class="math inline">\(d^{opt}\)</span> may be expressed in terms of the observed data under assumptions described in the section <a href="#Model_Setup_and_Assumptions">Model setup and Assumptions</a>.</p>
<blockquote>
<p>At the <span class="math inline">\(K\)</span>th decision point, for any <span class="math inline">\((\overline{x_{K}}, \overline{a_{K-1}}) \in \Gamma_{K}\)</span>, define
<span class="math display">\[\begin{align*}
d^{opt}_{K}(\overline{x_{K}}, \overline{a_{K-1}}) &amp;= \argmax_{a_{K} \in \Psi_{K}(\overline{x_{K}}, \overline{a_{K-1}})} \mathbb{E}[Y^{*}(\overline{a_{K-1}}, a_{K}) | \overline{X}_{K}^{*}(\overline{a_{K-1}}) = \overline{x_{K}}], \\
V_{K}^{}(\overline{x_{K}}, \overline{a_{K-1}}) &amp;= \max_{a_{K} \in \Psi_{K}(\overline{x_{K}}, \overline{a_{K-1}})} \mathbb{E}[Y^{*}(\overline{a_{K-1}}, a_{K}) | \overline{X}_{K}^{*}(\overline{a_{K-1}}) = \overline{x_{K}}].
\end{align*}\]</span></p>
</blockquote>
<p>Here, <span class="math inline">\(d^{opt}_{K}\)</span> is the treatment that maximizes the expected potential final outcome given the prior potential information, and <span class="math inline">\(V_{K}\)</span> is the achieved maximum.</p>
<blockquote>
<p>For <span class="math inline">\(k = K-1, \cdots, 1\)</span>, and any <span class="math inline">\((\overline{x_{k}}, \overline{a_{k-1}}) \in \Gamma_{k}\)</span>, let
<span class="math display">\[\begin{align*}
d^{opt}_{k}(\overline{x_{k}}, \overline{a_{k-1}}) &amp;= \argmax_{a_{k} \in \Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}})} \mathbb{E} \left[ V_{k+1}^{} \left(\underbrace{\overline{x_{k}}, X^{*}_{k+1}(\overline{a_{k-1}},a_{k})}_{=\overline{X}_{k+1}^{*} (\overline{a_{k}})}, \underbrace{\overline{a_{k-1}}, a_{k}}_{=\overline{a_{k}}} \right)  \bigg| \overline{X}_{k}^{*}(\overline{a_{k-1}}) = \overline{x_{k}} \right], \\
V_{k}^{}(\overline{x_{k}}, \overline{a_{k-1}}) &amp;= \max_{a_{k} \in \Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}})} \mathbb{E} \left[ V_{k+1}^{} \left(\underbrace{\overline{x_{k}}, X^{*}_{k+1}(\overline{a_{k-1}},a_{k})}_{ = \overline{X}_{k+1}^{*} (\overline{a_{k}})}, \underbrace{\overline{a_{k-1}}, a_{k}}_{=\overline{a_{k}}} \right)  \bigg| \overline{X}_{k}^{*}(\overline{a_{k-1}}) = \overline{x_{k}} \right].
\end{align*}\]</span></p>
</blockquote>
<p>Similarly, <span class="math inline">\(d^{opt}_{k}\)</span> is the <span class="math inline">\(k\)</span>th treatment that maximizes the <span class="math inline">\(k+1\)</span>th expected outcome that would be achieved if subsequent optimal rules already defined were followed henceforth. It shows how <span class="math inline">\(\mathbf{d}^{opt}=(d^{opt}_{1}, d^{opt}_{2}, \cdots, d^{opt}_{K})\)</span> is determined via backward induction, also known as dynamic programming. Proof will be added to show that <span class="math inline">\(\mathbf{d}^{opt}\)</span> defined in the above steps satisfies the condition <span class="math inline">\(\mathbb{E}[Y^{*}\big(\mathbf{d}\big)] \le \mathbb{E}[Y^{*}\big(\mathbf{d}^{opt}\big)], \text{ for all } \mathbf{d} \in \mathcal{D}\)</span>.</p>
<hr />
</div>
<div id="estimation_dtr" class="section level3">
<h3>Estimation of Optimal Treatment Regimes</h3>
<p>If an optimal regime is to be identifiable, we can express <span class="math inline">\(\mathbf{d}^{opt}\)</span> in terms of the distribution of the observed i.i.d. data <span class="math inline">\((X_{1i}, A_{1i}, \cdots, X_{Ki}, A_{Ki}, Y_{i}), i = 1, \cdots, n\)</span>.</p>
<blockquote>
<p>Then at the <span class="math inline">\(K\)</span> th decision point, define
<span class="math display">\[\begin{align*}
Q_{K}(\overline{x_{K}}, \overline{a_{K}}) &amp;= \mathbb{E} [Y|\overline{X_{K}}=\overline{x_{K}}, \overline{A_{K}}=\overline{a_{K}}], \\
d_{K}^{opt}(\overline{x_{K}}, \overline{a_{K-1}}) &amp;= \argmax_{a_{K} \in \Psi_{K}(\overline{x_{K}}, \overline{a_{K-1}})} Q_{K}(\overline{x_{K}}, \overline{a_{K-1}}, a_{K}), \\
V_{K}(\overline{x_{K}}, \overline{a_{K-1}}) &amp;= \max_{a_{K} \in \Psi_{K}(\overline{x_{K}}, \overline{a_{K-1}})}Q_{K}(\overline{x_{K}}, \overline{a_{K-1}}, a_{K}).
\end{align*}\]</span>
and for <span class="math inline">\(k = K-1, \cdots, 1,\)</span>
<span class="math display">\[\begin{align*}
Q_{k}(\overline{x_{k}}, \overline{a_{k}}) &amp;= \mathbb{E} [V_{k+1}(\overline{x_{k}}, X_{k+1}, \overline{a_{k}}) | \overline{X_{k}}=\overline{x_{k}}, \overline{A_{k}}=\overline{a_{k}}], \\
d_{k}^{opt}(\overline{x_{k}}, \overline{a_{k-1}}) &amp;= \argmax_{a_{k} \in \Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}})} Q_{k}(\overline{x_{k}}, \overline{a_{k-1}}, a_{k}), \\
V_{k}(\overline{x_{k}}, \overline{a_{k-1}}) &amp;= \max_{a_{k} \in \Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}})} Q_{k}(\overline{x_{k}}, \overline{a_{k-1}}, a_{k}). \\
\end{align*}\]</span></p>
</blockquote>
<p>Here, <span class="math inline">\(Q_{k}(\overline{x_{k}}, \overline{a_{k}})\)</span> are referred to as “Q-functions” viewed as measuring the <strong>quality</strong> associated with treatment <span class="math inline">\(a_{k}\)</span> at decision <span class="math inline">\(k\)</span> given the history up to that decision and then following the optimal regime therafter. <span class="math inline">\(V_{k}(\overline{x_{k}}, \overline{a_{k-1}})\)</span> are known as “value functions” viewed as the <strong>value</strong> of a patient’s history <span class="math inline">\(\overline{x_{k}}, \overline{a_{k-1}}\)</span> given that optimal decisions are made in the future.</p>
<p>In order to estimate an optimal regime, the treatment options in <span class="math inline">\(\Psi\)</span> must be represented in the data, which implies for <span class="math inline">\((\overline{x_{k}}, \overline{a_{k-1}}) \in \Gamma_{k}, \text{ and }a_{k} \in \Psi_{k}(\overline{x_{k}}, \overline{a_{k-1}}),\)</span>
<span class="math display">\[\begin{align*}
\mathbb{P}[ A_{k} = a_{k} | \overline{X_{k}} = \overline{x_{k}}, \overline{A_{k-1}} = \overline{a_{k-1}}] &gt; 0,
\end{align*}\]</span>
for all <span class="math inline">\(k = 1, \cdots, K\)</span>.</p>
<p>Then, estimation of <span class="math inline">\(\mathbf{d}^{opt}\)</span> may be accomplished via direct modeling and fitting of the Q-functions. Specifically, for <span class="math inline">\(k = K, K-1, \cdots, 1\)</span>, assume models <span class="math inline">\(Q_{k}(\overline{x_{k}}, \overline{a_{k}}; \xi_{k})\)</span> depending on a finite-dimensional parameter <span class="math inline">\(\xi_{k}\)</span>. The models may be linear or nonlinear in <span class="math inline">\(\xi_{k}\)</span>, and estimators <span class="math inline">\(\widehat{\xi_{k}}\)</span> can be obtained in a backward iteration for <span class="math inline">\(k = K, K-1, \cdots, 1\)</span> by solving suitable estimating equations including ordinary least squares (OLS) or weighted least squares (WLS) as follows.</p>
<p><span class="math display">\[\begin{align*}
\sum_{i=1}^n \frac{\partial Q_k\left(\overline{X_{k, i}}, \overline{A_{k,i}}; \xi_{k} \right)}{\partial \xi_{k}} \left[ \underbrace{\Sigma_{k}\left(\overline{X_{k, i}}, \overline{A_{k,i}} \right) }_{=: \text{Working Variance}} \right]^{-1} \left\{ \underbrace{\widetilde{V}_{(k+1), i}}_{=Y_{i} \text{ for } k=K} - Q_{k}\left(\overline{X_{k, i}}, \overline{A_{k,i}}; \xi_{k}\right) \right\} =0.
\end{align*}\]</span></p>
<blockquote>
<ol style="list-style-type: decimal">
<li><p>Solve the above estimating equations for <span class="math inline">\(k = K\)</span> in <span class="math inline">\(\xi_{K}\)</span> to obtain <span class="math inline">\(\widehat{\xi_{K}}\)</span>.</p>
<ul>
<li><span class="math inline">\(d_{K}^{opt}(\overline{x_{K}}, \overline{a_{K-1}}; \widehat{\xi_{K}}) = \argmax_{a_{K}} Q_{K}(\overline{x_{K}}, \overline{a_{K}}; \widehat{\xi_{K}})\)</span> : an estimator for the optimal treatment choice at decision <span class="math inline">\(K\)</span> for a patient with past history <span class="math inline">\(\overline{X_{K}}= \overline{x_{K}}, \overline{A_{K-1}}= \overline{a_{K-1}}\)</span>.</li>
</ul></li>
<li><p>Solve the estimating equation for <span class="math inline">\(k = K-1\)</span> with <span class="math inline">\(\widehat{\xi_{K-1}}\)</span> in <span class="math inline">\(\xi_{K-1}\)</span>.</p>
<ul>
<li>With <span class="math inline">\(\widehat{\xi_{K}}\)</span>, one would form
<span class="math display">\[\begin{align*}
\widetilde{V}_{K,i} = \max_{a_{K} \in \Psi_{K}}Q_{K} \left(\overline{X_{K,i}}, \overline{A_{(K-1),i}}, a_{K}; \widehat{\xi_{K}} \right) \text{ for each } i.
\end{align*}\]</span></li>
<li><span class="math inline">\(d_{K-1}^{opt}(\overline{x_{K-1}}, \overline{a_{K-2}}; \widehat{\xi_{K-1}}) = \argmax_{a_{K-1}} Q_{K-1}(\overline{x_{K-1}}, \overline{a_{K-1}}; \widehat{\xi_{K-1}})\)</span>: an estimator for the optimal treatment choice at decision <span class="math inline">\(K-1\)</span> for a patient with past history <span class="math inline">\(\overline{X_{K-1}}= \overline{x_{K-1}}, \overline{A_{K-2}}= \overline{a_{K-2}}\)</span>, assuming that a patient will take the optimal treatment at decision <span class="math inline">\(K\)</span>.</li>
</ul></li>
<li><p>Continue this process in the backward manner for <span class="math inline">\(k= K-2, \cdots, 1\)</span>.</p></li>
</ol>
</blockquote>
<p>Then we may summarize the estimated optimal regime as <span class="math inline">\(\widehat{\mathbf{d}}^{opt} = (\widehat{d}^{opt}_{1}, \widehat{d}^{opt}_{2}, \cdots, \widehat{d}^{opt}_{K})\)</span>, where
<span class="math display">\[\begin{align*}
&amp; \widehat{d}^{opt}_{1}(x_{1}) = d_{1}^{opt}(x_{1}; \widehat{\xi_{1}}), \\
&amp; \widehat{d}^{opt}_{k}(\overline{x_{k}}, \overline{a_{k-1}}) = d_{k}^{opt}(\overline{x_{k}}, \overline{a_{k-1}}; \widehat{\xi_{k}}), \quad k = 2, \cdots, K.
\end{align*}\]</span></p>
<p>Since we have presented estimating equations in the weighted least squares form, at the <span class="math inline">\(K\)</span>th decision with responses <span class="math inline">\(Y_{i}\)</span>, it is known that it is possible to get asymptotically efficient estimator for <span class="math inline">\(\xi_{K}\)</span> when <span class="math inline">\(Var(Y|\overline{X_{k}}= \overline{x_{k}}, \overline{A_{k}} = \overline{a_{k}}) = \Sigma_{k}(\overline{x_{k}}, \overline{a_{k}})\)</span>. On the other hand, for <span class="math inline">\(k &lt; K\)</span> with responses <span class="math inline">\(\widetilde{V}_{(k+1),i}\)</span>, the theory may no longer apply. However, since deriving the optimal term is considerably complicated, it is standard to fit the model via OLS or WLS.</p>
<div id="star-estimation-for-k-2" class="section level4">
<h4><span class="math inline">\(\star\)</span> Estimation for <span class="math inline">\(K = 2\)</span> :</h4>
<p>Now we illustrate this approach for <span class="math inline">\(K = 2\)</span>, where at each decision, there are two possible treatment options coded as 0 and 1. Let us first define history at time <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> as <span class="math inline">\(\mathcal{H}_{1}:= (1, x_{1}^{T})^{T}\)</span> and <span class="math inline">\(\mathcal{H}_{2}:= (1, x_{1}^{T}, a_{1}, x_{2}^{T})^{T}\)</span>, respectively. Here, we assume linear models for the Q-functions as follows.</p>
<p><span class="math display">\[\begin{align*}
&amp; Q_{1}(x_{1}, a_{1}; \boldsymbol{\xi}_{1}) \hspace{1cm} := \mathcal{H}_{1}^{T} \boldsymbol{\beta}_{1} + a_{1} (\mathcal{H}_{1}^{T} \boldsymbol{\gamma}_{1}) \\
&amp; Q_{2}(x_{1}, a_{1}, x_{2}, a_{2}; \boldsymbol{\xi}_{2}) := \mathcal{H}_{2}^{T} \boldsymbol{\beta}_{2} + a_{2} (\mathcal{H}_{2}^{T} \boldsymbol{\gamma}_{2})
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\xi}_{k} = (\boldsymbol{\beta}_{k}, \boldsymbol{\gamma}_{k})^{T}\)</span> for <span class="math inline">\(k = 1, 2\)</span>.</p>
<p>By definition,</p>
<p><span class="math display">\[\begin{align*}
V_{2} (x_{1}, a_{1}, x_{2}; \boldsymbol{\xi}_{2}) &amp;= \max_{a_{2}} Q_{2} (x_{1}, a_{1}, x_{2}, a_{2}; \boldsymbol{\xi}_{2}) \\
&amp;= \max_{a_{2}} \left[ \mathcal{H}_{2}^{T} \boldsymbol{\beta}_{2} + a_{2} (\mathcal{H}_{2}^{T} \boldsymbol{\gamma}_{2}) \right] \\
&amp;= \mathcal{H}_{2}^{T} \boldsymbol{\beta}_{2} + \mathcal{H}_{2}^{T} \boldsymbol{\gamma}_{2} \,\, \mathbf{1}\left(\mathcal{H}_{2}^{T} \boldsymbol{\gamma}_{2} &gt; 0 \right), \\
V_{1} (x_{1}; \boldsymbol{\xi}_{1}) &amp;= \max_{a_{1}} Q_{1} (x_{1}, a_{1}; \boldsymbol{\xi}_{1}) \\
&amp;= \max_{a_{1}} \left[ \mathcal{H}_{1}^{T} \boldsymbol{\beta}_{1} + a_{1} (\mathcal{H}_{1}^{T} \boldsymbol{\gamma}_{1}) \right] \\
&amp;= \mathcal{H}_{1}^{T} \boldsymbol{\beta}_{1} + \mathcal{H}_{1}^{T} \boldsymbol{\gamma}_{1} \,\, \mathbf{1}\left(\mathcal{H}_{1}^{T} \boldsymbol{\gamma}_{1} &gt; 0 \right).
\end{align*}\]</span></p>
<p>which implies <span class="math inline">\(d_{1}^{opt}(x_{1}; \boldsymbol{\xi}_{1}) = \mathbf{1}\left(\mathcal{H}_{1}^{T} \boldsymbol{\gamma}_{1} &gt; 0 \right), \,\, d_{2}^{opt}(x_{1}, a_{1}, x_{2}; \boldsymbol{\xi}_{2}) = \mathbf{1}\left(\mathcal{H}_{2}^{T} \boldsymbol{\gamma}_{2} &gt; 0 \right)\)</span>.</p>
<p>In this example, we follow the steps below based on ordinary least squares to estimate optimal dynamic treatment rule:</p>
<ol style="list-style-type: decimal">
<li><p>Estimate <span class="math inline">\(\boldsymbol{\xi}_{2}= ({\boldsymbol{\beta}}_{2}, {\boldsymbol{\gamma}}_{2}).\)</span>
<span class="math display">\[\begin{align*}
(\widehat{\boldsymbol{\beta}}_{2}, \widehat{\boldsymbol{\gamma}}_{2}) &amp;= \argmin_{\beta_{2}, \gamma_{2}} \frac{1}{n} \sum_{i=1}^{n} \left(Y_{i} - Q_{2}(X_{1}, A_{1}, X_{2}, A_{2}; \beta_{2}, \gamma_{2}) \right)^{2} \\
&amp;= \argmin_{\beta_{2}, \gamma_{2}} \frac{1}{n} \sum_{i=1}^{n} \left(Y_{i} - \mathcal{H}_{2,i}^{T} \boldsymbol{\beta}_{2} - A_{2,i} \mathcal{H}_{i,2}^{T} \boldsymbol{\gamma}_{2} \right)^{2} \\
\end{align*}\]</span></p></li>
<li><p>Calculate <span class="math inline">\(\widetilde{V_{1,i}}\)</span> for <span class="math inline">\(i=1,\cdots,n.\)</span>
<span class="math display">\[\begin{align*}
\widetilde{V_{1,i}} &amp;= \max_{a_{2}} \left[Q_{2}(X_{1}, A_{1}, X_{2}, A_{2}; \widehat{\beta}_{2}, \widehat{\gamma}_{2}) \right]\\
&amp;= \max_{a_{2}} \left[ \mathcal{H}_{2,i}^{T} \widehat{\boldsymbol{\beta}}_{1} - A_{2,i} \mathcal{H}_{i,2}^{T} \widehat{\boldsymbol{\gamma}}_{2} \right].
\end{align*}\]</span></p></li>
<li><p>Estimate <span class="math inline">\(\boldsymbol{\xi}_{1}= ({\boldsymbol{\beta}}_{1}, {\boldsymbol{\gamma}}_{2}).\)</span>
<span class="math display">\[\begin{align*}
(\widehat{\boldsymbol{\beta}}_{1}, \widehat{\boldsymbol{\gamma}}_{1}) &amp;= \argmin_{\beta_{1}, \gamma_{1}} \frac{1}{n} \sum_{i=1}^{n} \left( \widetilde{V_{1,i}} - Q_{1}(X_{1}, A_{1}; \beta_{1}, \gamma_{1}) \right)^{2} \\
&amp;= \argmin_{\beta_{1}, \gamma_{1}} \frac{1}{n} \sum_{i=1}^{n} \left(\widetilde{V_{1,i}} - \mathcal{H}_{1,i}^{T} \boldsymbol{\beta}_{2} - A_{1,i} \mathcal{H}_{i,1}^{T} \boldsymbol{\gamma}_{1} \right)^{2} \\
\end{align*}\]</span></p></li>
<li><p>Estimate the optimal treatment <span class="math inline">\(\mathbf{d}^{opt}=(\mathbf{d}_{1}^{opt}, \mathbf{d}_{2}^{opt}).\)</span>
<span class="math display">\[\begin{align*}
&amp; \widehat{d}_{1}^{opt}(x_{1}; \widehat{\boldsymbol{\xi}}_{1}) \hspace{1cm} =
\mathbf{1}\left(\mathcal{H}_{1}^{T} \widehat{\boldsymbol{\gamma}}_{1} &gt; 0 \right), \\
&amp; \widehat{d}_{2}^{opt}(x_{1}, a_{1}, x_{2}; \widehat{\boldsymbol{\xi}}_{2}) = \mathbf{1}\left(\mathcal{H}_{2}^{T} \widehat{\boldsymbol{\gamma}}_{2} &gt; 0 \right).
\end{align*}\]</span></p></li>
</ol>
<hr />
</div>
</div>
<div id="estimation" class="section level3">
<h3>Estimation of Potential Outcome</h3>
<p>In this section, consider a fixed treatment <span class="math inline">\((a_{1}, a_{2}) \in \{0,1\}^{2}\)</span> with two time points <span class="math inline">\(K = 2\)</span>. We are interested in estimating the expected potential outcome <span class="math inline">\(\mathbb{E}[Y(a_{1}, a_{2})]\)</span> of treatment <span class="math inline">\((a_{1}, a_{2})\)</span> using weighted observed outcome <span class="math inline">\(W \mathbb{1}(A_{1} = a_{1}, A_{2} = a_{2})Y\)</span> when the random treatment used <span class="math inline">\((A_{1}, A_{2})\)</span> in fact agrees with the desired treatment <span class="math inline">\((a_{1}, a_{2})\)</span>. We have the following lemma below based on inverse probability weighting.</p>
<p><br />
</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-5" class="lemma"><strong>Lemma 3  </strong></span><em>Fix a treatment <span class="math inline">\((a_{1},a_{2})\in \{0,1\}^{2}\)</span>. Under the assumptions of consistency, SUTVA, and sequential ignorability mentioned in the section <a href="#Model_Setup_and_Assumptions">Model setup and assumptions</a>, we have</em>
<span class="math display">\[\begin{align*}
&amp;\mathbb{E}[Y^{*}(a_{1}, a_{2})] \\
&amp;= \mathbb{E}_{(X_{1}, A_{1}, X_{2}, A_{2}, Y)} \left[ \frac{Y \mathbf{1}(A_{1} = a_{1})}{\mathbf{P}(A_{1} = a_{1}|X_{1})}\frac{\mathbf{1}(A_{2} = a_{2})}{\mathbf{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})}\right] \\
&amp;= \mathbb{E} \left[ W \mathbf{1}(A_1 = a_1, A_2 = a_2) Y\right]
\end{align*}\]</span>
where <span class="math inline">\(W = \mathbf{P}(A_{1} = a_{1}|X_{1})^{-1}, \mathbf{P}(A_{2} = a_{2} | X_{2}, A_{1} = a_{1}, X_{1})^{-1}\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-6" class="proof"><em>Proof</em>. </span><span class="math inline">\({}\)</span>
Using iterated expectations, consistency, and sequential ignorability, we have
<span class="math display">\[\begin{align*}
&amp; \mathbb{E}_{(X_{1}, A_{1}, X_{2}, A_{2}, Y)} \left[ \frac{Y \mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1})}\frac{\mathbf{1}(A_{2} = a_{2})}{\mathbb{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})}\right] \\
&amp; \qquad \overset{(a)}{=} \mathbb{E}_{(X_{1}, A_{1}, X_{2}, A_{2}, Y^{*})} \left[ \frac{Y^{*}(a_{1}, a_{2})}{\mathbb{P}(A_{1} = a_{1}|X_{1})}\frac{\mathbf{1}(A_{1} = a_{1}) \mathbf{1}(A_{2} = a_{2})}{\mathbb{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})}\right] \\
    &amp; \qquad = \mathbb{E}_{(X_{1}, A_{1}, X_{2})} \left[ \mathbb{E}_{(A_{2}, Y^{*})} \left[ \frac{Y^{*}(a_{1}, a_{2})}{\mathbb{P}(A_{1} = a_{1}|X_{1})}\frac{\mathbf{1}(A_{1} = a_{1}) \mathbf{1}(A_{2} = a_{2})}{\mathbb{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})} \bigg| X_{1}, A_{1}, X_{2} \right] \right] \\
    &amp; \qquad = \mathbb{E}_{(X_{1}, A_{1}, X_{2})} \left[ \frac{\mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1}) \mathbb{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})} \,\, \mathbb{E}_{(A_{2}, Y^{*})} \left[ Y^{*}(a_{1}, a_{2})\mathbf{1}(A_{2} = a_{2}) \bigg| X_{1}, A_{1}, X_{2} \right] \right] \\
    &amp; \qquad \overset{(b)}{=} \mathbb{E}_{(X_{1}, A_{1}, X_{2})} \left[ \frac{\mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1}) \mathbb{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})} \,\, \mathbb{E}_{Y^{*}} \left[ Y^{*}(a_{1}, a_{2}) \bigg| X_{1}, A_{1}, X_{2} \right] \mathbb{E}_{A_{2}} \left[\mathbf{1}(A_{2} = a_{2}) \bigg| X_{1}, A_{1} = a_{1}, X_{2} \right] \right] \\
    &amp; \qquad = \mathbb{E}_{(X_{1}, A_{1}, X_{2})} \left[ \frac{\mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1}) \mathbb{P}(A_{2} = a_{2} | X_{1}, A_{1} = a_{1}, X_{2})} \,\, \mathbb{E}_{Y^{*}} \left[ Y^{*}(a_{1}, a_{2}) \bigg| X_{1}, A_{1}, X_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \bigg| X_{1}, A_{1} = a_{1}, X_{2} \right) \right] \\
    &amp; \qquad = \mathbb{E}_{(X_{1}, A_{1}, X_{2})} \left[ \frac{\mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1})} \,\, \mathbb{E}_{Y^{*}} \left[ Y^{*}(a_{1}, a_{2}) \bigg| X_{1}, A_{1}, X_{2} \right] \right] \\
    &amp; \qquad = \mathbb{E}_{(X_{1}, A_{1}, X_{2}, Y^{*})} \left[ \frac{Y^{*}(a_{1}, a_{2}) \mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1})} \right] \\
    &amp; \qquad = \mathbb{E}_{X_{1}} \left[ \mathbb{E}_{(A_{1}, X_{2}, Y^{*})} \left[ \frac{Y^{*}(a_{1}, a_{2})\mathbf{1}(A_{1} = a_{1})}{\mathbb{P}(A_{1} = a_{1}|X_{1})} \bigg| X_{1} \right] \right] \\
    &amp; \qquad = \mathbb{E}_{X_{1}} \left[ \frac{1}{\mathbb{P}(A_{1} = a_{1}|X_{1})} \,\, \mathbb{E}_{(A_{1}, X_{2}, Y^{*})}  \left[ Y^{*}(a_{1}, a_{2})\mathbf{1}(A_{1} = a_{1}) \bigg| X_{1} \right] \right] \\
    &amp; \qquad \overset{(c)}{=} \mathbb{E}_{X_{1}} \left[ \frac{1}{P(A_{1} = a_{1}|X_{1})} \,\, \mathbb{E}_{(X_{2}, Y^{*})}  \left[ Y^{*}(a_{1}, a_{2}) \bigg| X_{1} \right] \mathbb{E}_{A_{1}}  \left[\mathbf{1}(A_{1} = a_{1}) \bigg| X_{1} \right] \right] \\
    &amp; \qquad = \mathbb{E}_{X_{1}} \left[ \frac{1}{\mathbb{P}(A_{1} = a_{1}|X_{1})} \,\, \mathbb{E}_{(X_{2}, Y^{*})}  \left[ Y^{*}(a_{1}, a_{2}) \bigg| X_{1} \right] \mathbb{P} \left(A_{1} = a_{1} \bigg| X_{1} \right) \right] \\
    &amp; \qquad = \mathbb{E}_{X_{1}} \left[ \mathbb{E}_{(X_{2}, Y^{*})}  \left[ Y^{*}(a_{1}, a_{2}) \bigg| X_{1} \right] \right] \\
    &amp; \qquad = \mathbb{E}_{(X_{1}, X_{2}, Y^{*})} \bigg[Y^{*}(a_{1}, a_{2})  \bigg] \\
    &amp; \qquad = \mathbb{E} [Y^{*}(a_{1}, a_{2})]
\end{align*}\]</span>
where <span class="math inline">\((b)\)</span> and <span class="math inline">\((c)\)</span> use the sequential ignorability assumptions <span class="math inline">\(Y^{*}(a_{1}, a_{2}) \perp A_{2} \, | \, (X_{1}, A_{1}, X_{2})\)</span>, <span class="math inline">\(Y^{*}(a_{1}, a_{2}) \perp A_{1} | X_{1}\)</span>, respectively, and <span class="math inline">\((a)\)</span> uses the fact <span class="math inline">\(Y \mathbf{1}(A_{1} = a_{1}) \mathbf{1}(A_{2} = a_{2}) = Y(A_{1}, A_{2}) \mathbf{1}(A_{1} = a_{1}) \mathbf{1}(A_{2} = a_{2}) = Y^{*}(a_{1}, a_{2}) \mathbf{1}(A_{1} = a_{1}) \mathbf{1}(A_{2} = a_{2})\)</span> using consistency.
<span class="math display">\[\begin{align*}
\hspace{15cm} \square
\end{align*}\]</span></p>
</div>
<hr />
</div>
<div id="simulation" class="section level3">
<h3>Simulation Studies</h3>
<p>For simiulation, generating data process mimics a study in which HIV-infected patients are randomized to receive antiretroviral therapy (coded as 1) or not (coded as 0) at baseline and at six months. The randomization probabilities depend on baseline and six month CD4 counts. The detailed generating process is as follows.</p>
<blockquote>
<ul>
<li><span class="math inline">\(X_{1} \sim N(450, 150^2)\)</span> : baseline CD4 count</li>
<li><span class="math inline">\(A_{1} | X_{1} = x_{1} \sim \text{Ber}\left[\text{expit}(-0.006 x_{1} + 2)\right]\)</span> : treatment <span class="math inline">\(A_{1}\)</span></li>
<li><span class="math inline">\(X_{2} | X_{1} = x_{1}, A_{1} = a_{1} \sim N(1.25 x_{1}, 60^2)\)</span> : six month CD4 count</li>
<li><span class="math inline">\(\small{A_{2} | X_{1} = x_{1}, A_{1} = a_{1}, X_{2} = x_{2} \sim \text{Ber}\left[\text{expit}(-0.004 x_{2} + 0.8)\right]}\)</span> : treatment <span class="math inline">\(A_{2}\)</span></li>
<li><span class="math inline">\(Y = Y^{opt} - \mu_{1}(X_{1}, A_{1}) - \mu_{2}(X_{1}, A_{1}, X_{2}, A_{2})\)</span> : CD4 count at one year
<ul>
<li><span class="math inline">\(Y^{opt} | X_{1} = x_{1}, A_{1} = a_{1}, X_{2} = x_{2}, A_{2} = a_{2} \sim \hspace{1cm} N(1.6 x_{1} + 400, 60^2)\)</span></li>
<li><span class="math display">\[\begin{align*}
\mu_{1}(X_{1}, A_{1}) &amp;= (\gamma_{10} + \gamma_{11} X_{1}) \left[ \mathbf{1}(\gamma_{10} + \gamma_{11} X_{1} &gt; 0) - A_{1} \right] \\
&amp;\overset{(set)}{=} (250 - X_{1}) \left[ \mathbf{1}(250 - X_{1} &gt; 0) - A_{1} \right]
\end{align*}\]</span></li>
<li><span class="math display">\[\begin{align*}
\mu_{2}(X_{1}, A_{1}, X_{2}, A_{2}) &amp;= (\gamma_{20} + \gamma_{21} X_{2}) \left[ \mathbf{1}((\gamma_{20} + \gamma_{21} X_{2}) &gt; 0) - A_{2} \right] \\
&amp;\overset{(set)}{=} (720 -2X_{2}) \left[\mathbf{1}(720 -2 X_{2} &gt; 0) - A_{2} \right]
\end{align*}\]</span></li>
</ul></li>
</ul>
</blockquote>
<p>where <span class="math inline">\(\text{expit}(x) = e^{x}/(e^{x}+1)\)</span>, and <span class="math inline">\(\mu_{1}(X_{1}, A_{1}), \mu_{2}(X_{1}, A_{1}, X_{2}, A_{2})\)</span> are true advantage functions in response if the optimal treatment at each decision were given relative to that actually received. Then the true optimal treatment regime is <span class="math inline">\(d_{1}^{opt}(x_{1}) = \mathbf{1}(250 - X_{1} &gt; 0)\)</span> and <span class="math inline">\(d_{2}^{opt}(x_{1}, a_{1}, x_{2}) = \mathbf{1}(720 -2 X_{2} &gt; 0)\)</span>.</p>
<p>For Q-learning, we assumed working models
<span class="math display">\[\begin{align*}
&amp; Q_{1}(x_{1}, a_{1}; \boldsymbol{\xi}_{1}) \hspace{1cm} := \beta_{10} + \beta_{11} x_{1} + a_{1} (250 - x_{1}) \\
&amp; Q_{2}(x_{1}, a_{1}, x_{2}, a_{2}; \boldsymbol{\xi}_{2}) :=
\beta_{20} + \beta_{21} x_{1} + \beta_{22} a_{1} +  \beta_{23} x_{1} a_{1} +  \beta_{24} x_{2} +  a_{2} (720 -2 x_{2})
\end{align*}\]</span></p>
<p>With <span class="math inline">\(n=1000\)</span>, we have the following results:</p>
<p><span class="math display">\[\begin{align*}
\begin{aligned}
&amp;\begin{array}{ccc}
\text { Time } &amp; \text{ True parameter } &amp; \text { Estimated parameter }  &amp; \text{ Predicted ITR Accuracy }  \\
\hline
1 &amp; \gamma_{10} = 250 &amp; 155.49 (21.76) &amp; 0.957 (0.012) \\
1 &amp; \gamma_{11} = -1.0 &amp; -0.78 (0.05)  &amp;- \\
2 &amp; \gamma_{20} = 720  &amp; 506.50 (48.78) &amp;0.957 (0.014) \\
2 &amp; \gamma_{21} = -2.0 &amp; -1.58 (0.09) &amp;- \\
\hline
\end{array}
\end{aligned}
\end{align*}\]</span></p>
<details>
<summary>
Click for code
</summary>
<pre class="r"><code>expit &lt;- function(x){ exp(x)/(1+exp(x)) }

simulated_dtr &lt;- function(iter = 3){
  
  n = 1000
  result = list()
  result[[1]] = array(0, dim = c(2, 2, iter))
  result[[2]] = array(0, dim = c(2, 2, iter))
  result_cutoff = data.frame(cutoff_X1 = 0, cutoff_X2 = 0,
                             slope_X1 = 0, slope_X2 = 0)
  result_outcome = data.frame(mean_Y_est_itr = 0, mean_Y_itr = 0)

  for (i in 1:iter){
    set.seed(i)
    
    # Generate dataset
    X1 = rnorm(n, mean = 450, sd = 150) 
    A1 = rbinom(n, size = 1, prob = expit(-0.006 * X1 + 2)) 
    X2 = rnorm(n, mean = 1.25 * X1, sd = 60)
    A2 = rbinom(n, size = 1, prob = expit(-0.004*X2 + 0.8)) 
    Y_opt = rnorm(n, mean = 400 + 1.6 * X1, sd = 60) 
    mu_1 = (250 - X1) * ( ifelse(250 - X1 &gt; 0, 1, 0) - A1 ) 
    mu_2 = (720 - 2 * X2) * ( ifelse(720 - 2 * X2 &gt; 0, 1, 0) - A2 ) 
    Y = Y_opt - mu_1 - mu_2
    
    # True optimal ITR
    d1_opt = ifelse(250 - X1 &gt; 0, 1, 0) 
    d2_opt = ifelse(720 - 2 * X2 &gt; 0, 1, 0) 
    
    # Estimate DTR
    xi_2 = lm(Y ~ X1 + A1 + X1*A1 + X2 + A2 + A2*X2)
    pred_A2 = as.numeric(ifelse(cbind(1, X2) %*% coef(xi_2)[c(5,7)]&gt;0, 1, 0))
    v_1 = as.numeric(cbind(1, X1, A1, X2, X1*A1) %*% coef(xi_2)[c(1:4, 6)] 
                     + pred_A2 * cbind(1, X2) %*% coef(xi_2)[c(5,7)])
    xi_1 = lm(v_1 ~ X1 + A1 + A1*X1)
    pred_A1 = as.numeric(ifelse(cbind(1, X1) %*% coef(xi_1)[3:4]&gt;0, 1, 0))
    
    # Estimate potential outcome
    
    ## propensity score model
    ps1_model = glm(A1 ~ X1, family = binomial(link = &quot;logit&quot;))
    ps1 = predict(ps1_model, type = &quot;response&quot;)
    ps2_model = glm(A2 ~ X1 + A1 + X2, family = binomial(link = &quot;logit&quot;))
    ps2 = predict(ps2_model, type = &quot;response&quot;)

    ## IPW
    weight = rep(0, n)
    weight[A1 == 1 &amp; A2 == 1] = 
      ps1[A1 == 1 &amp; A2 == 1] * ps2[A1 == 1 &amp; A2 == 1]
    weight[A1 == 1 &amp; A2 == 0] = 
      ps1[A1 == 1 &amp; A2 == 0] * (1-ps2[A1 == 1 &amp; A2 == 0])
    weight[A1 == 0 &amp; A2 == 1] = (1-ps1[A1 == 0 &amp; A2 == 1]) * 
      ps2[A1 == 0 &amp; A2 == 1]
    weight[A1 == 0 &amp; A2 == 0] = (1-ps1[A1 == 0 &amp; A2 == 0]) * 
      (1-ps2[A1 == 0 &amp; A2 == 0])
    weight = 1/weight

    msm = lm(Y ~ A1 + A2, weights = weight)

    ## Potential outcome
    mean_outcome_est_itr = 
      mean(predict(msm, data.frame(A1 = pred_A1, A2 = pred_A2)))
    mean_outcome_itr = 
      mean(predict(msm, data.frame(A1 = d1_opt, A2 = d2_opt)))
    
    # Result
    result_cutoff = rbind(result_cutoff, 
                          c(coef(xi_1)[3], coef(xi_2)[5],
                            coef(xi_1)[4], coef(xi_2)[7]))
    result_outcome = rbind(result_outcome, 
                          c(mean_outcome_est_itr, mean_outcome_itr))
    result[[1]][,,i] = table(d1_opt, pred_A1)                    
    result[[2]][,,i] = table(d2_opt, pred_A2)
  }
  result_cutoff = result_cutoff[-1,];
  result_outcome = result_outcome[-1,]
  result[[3]] = result_cutoff
  result[[4]] = result_outcome
  return(result)
}

sim_result = simulated_dtr(1000)
accuracy &lt;- apply(sim_result[[1]], 3, function(x) {(x[1,1]+x[2,2])/1000})
accuracy2 &lt;- apply(sim_result[[2]], 3, function(x) {(x[1,1]+x[2,2])/1000})
mean(accuracy); sd(accuracy)
mean(accuracy2); sd(accuracy2)
apply(sim_result[[3]], 2, mean)
apply(sim_result[[3]], 2, sd)
apply(sim_result[[4]], 2, mean)
apply(sim_result[[4]], 2, sd)</code></pre>
</details>
<p>Based on the estimated optimal regime, the first therapy is given to patients with baseline CD4 count less than 155.49, while the true optimal CD4 threshold is 250. Similarly, at the second decision, the second therapy is given to patients with six month CD4 count less than 506.50, while the true optimal CD4 threshold is 720.</p>
<p>Although Q-learning yields poor estimation of parameters, the estimated optimal regime shows 95% accuracy. Also, the estimated potential outcome with optimal ITR under marginal structural model is <span class="math inline">\(\widehat{\mathbb{E}}(\mathbb{d}^{opt}) = 1002.53\)</span> (standard deviation of 22.83) and one with predicted ITR is <span class="math inline">\(\widehat{\mathbb{E}}(\widehat{\mathbb{d}}^{opt}) = 1028.47\)</span> (standard deviation of 26.97), which is smaller difference compared to the difference of parameters.</p>
<p>The reason why the estimated parameters do not achieve the true optimal CD4 threshold is that the Q-functions are misspecified. More specifically, the linear models of <span class="math inline">\(f(\beta_{k})=H_{k}^{T}\beta_{k}\)</span> for <span class="math inline">\(k=1, 2\)</span> are poor approximations to the complex forms of the true models. This is why people introduced ‘Advantage learning (A-learning)’ because the entire Q-functions may not be directly specified to estimate the optimal regime. We will discuss more this topic.</p>
<hr />
</div>
<div id="sensitivity" class="section level3">
<h3>Sensitivity Analysis</h3>
<p>In the previous section, the estimation approach for optimal treatment rule <span class="math inline">\(\mathbb{d}^{opt}\)</span> is based on the following assumptions:</p>
<ul>
<li>Consistency assumption : <span class="math inline">\(X_{k} = X^{*}_{k}\big(\overline{A_{k-1}}\big), k=2, \cdots, K\)</span> and <span class="math inline">\(Y=Y^{*}\big(\overline{A_{k}}\big)\)</span>,</li>
<li>Stable unit treatment value assumption (well-defined) : a patient’s covariates and outcome are not affected by treatment assignment and other patients,</li>
<li>Sequential Ignorability : <span class="math inline">\(A_{k} \perp W^{*} | \{\overline{X_{k}}, \overline{A_{k-1}} \}, k=1, \cdots, K\)</span>.</li>
</ul>
<p>Based on these assumptions, we were able to identify and estimate the causal effect, which eventually allows us to find the optimal treatment rule.</p>
<p>In this section, we consider the situation where the sequential ignorability assumption is violated due to the existence of unmeasured confounder <span class="math inline">\(U_{k}\)</span> for <span class="math inline">\(k = 1, \cdots, K\)</span>. Then the potential outcome <span class="math inline">\(\mathbb{E}[Y^{*}(\overline{a_{k}})]\)</span> cannot be identified by the statistical estimand. The alternative approach is to find the possible range of values of the causal estimand in the presence of <span class="math inline">\(U_{k}\)</span> based on <strong>Manski bound</strong>.</p>
<p>Before we start, let us first define average treatment effect (ATE). Different from a single stage problem, there is no single definition of average treatment effect for time-varying covariates because there are <span class="math inline">\(2^{K}\)</span> possible combinations of treatment strategies. For static treatment, the number of possible contrasts is <span class="math inline">\({2^{K} \choose 2}\)</span>. For example, there are <span class="math inline">\(6\)</span> contrasts for <span class="math inline">\(K = 2\)</span> such as <span class="math inline">\(\mathbb{E}[Y(1, 1) - Y(0, 0)]\)</span> and <span class="math inline">\(\mathbb{E}[Y(1, 1) - Y(1, 0)]\)</span>. Under the dynamic treatment rule, the definition of ATE is even more complicated since treatment assignment at time <span class="math inline">\(k\)</span> depends on the evolving individual characteristics . For the following derivation, we will use a <strong>regret function</strong> introduced by Murphy (2003). Regret function <span class="math inline">\(R_{k}\)</span> at each time point <span class="math inline">\(k = 1, \cdots, K\)</span> is defined as the expected difference in the outcome had the optimal treatment <span class="math inline">\(d^{opt}_{k}\)</span> been taken at <span class="math inline">\(k\)</span> instead of treatment <span class="math inline">\(a_{k}\)</span> among those who received treatment <span class="math inline">\(\overline{a_{k}}\)</span> up to time <span class="math inline">\(k\)</span> and the optimal regime from <span class="math inline">\(k+1\)</span> onward. Then under <span class="math inline">\(K = 2\)</span>, the regret functions <span class="math inline">\(R_{1}\)</span> and <span class="math inline">\(R_{2}\)</span> are defined as:</p>
<blockquote>
<p><span class="math display">\[\begin{align*}
R_{1}(x_{1}, a_{1}) := &amp;  \mathbb{E}\left[ Y^{*}(d^{opt}_{1}(x_{1}), d_{2}^{opt}(x_{1}, d^{opt}_{1}(x_{1}), X^{*}_{2}(d^{opt}_{1}))) - Y^{*}(a_{1}, d_{2}^{opt}(x_{1}, a_{1}, X^{*}_{2}(a_{1}))) \, \bigg| \, X_{1} = x_{1} \right], \\
R_{2}(\overline{x_{2}}, a_{1}, a_{2}) := &amp; \mathbb{E}\left[Y^{*}(a_{1}, d_{2}^{opt}(x_{1}, a_{1}, x_{2})) - Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1} = x_{1}, A_{1} = a_{1}, X_{2} = x_{2} \right] \\
\end{align*}\]</span></p>
</blockquote>
<p>where <span class="math inline">\(d^{opt}_{1} := d^{opt}_{1}(x_{1})\)</span> and <span class="math inline">\(d_{2}^{opt} = d_{2}^{opt}(x_{1}, a_{1}, X^{*}_{2}(a_{1}))\)</span>. If the regret <span class="math inline">\(R_{k}\)</span> is greater than <span class="math inline">\(0\)</span>, we <em>regret</em> the choice of treatment. On the other hand, if <span class="math inline">\(R_{k}=0\)</span> (no regret), we can say that we make an ideal choice, therefore, <span class="math inline">\(d^{opt}_{k}\)</span> satisfies <span class="math inline">\(R_{k}(\overline{X_{k}}, \overline{a_{k-1}}, d^{opt}_{k})=0\)</span> for <span class="math inline">\(k = 1, 2\)</span>.</p>
<p>Here, we consider a fixed treatment <span class="math inline">\((a_{1}, a_{2}) \in \{0, 1\}^{2}\)</span> under two time points <span class="math inline">\(K = 2\)</span> and bounded outcome <span class="math inline">\(Y \in [Y_{l}, Y_{u}]\)</span>. The goal is to find the possible range of values of <span class="math inline">\(R_{k}\)</span> in the presence of unmeasured confounder <span class="math inline">\(U_{k}\)</span>. Then we have the following modified assumptions:</p>
<blockquote>
<p><span class="math display">\[\begin{align*}
&amp; 1. \quad Y^{*}(a_{1}, a_{2}) \perp A_{1} \,\, | \,\, \{X_{1}, U_{1}\},  \quad Y^{*}(a_{1}, a_{2}) \perp A_{2}  \,\, | \,\,  \{X_{1}, U_{1}, A_{1}, X_{2}, U_{2} \}, \\
&amp; 2. \quad 0 &lt; \mathbb{P}(A_{1} = a_{1} | X_{1} = x_{1}, U_{1} = u_{1}) &lt;1, \\
&amp; \hspace{0.7cm} 0 &lt; \mathbb{P}(A_{2} = a_{2} | X_{1} = x_{1}, U_{1} = u_{1}, A_{1} = a_{1}, X_{2} = x_{2}, U_{2} = u_{2}) &lt;1. \\
\end{align*}\]</span></p>
</blockquote>
<div id="regret-at-second-stage" class="section level4">
<h4>Regret at second stage</h4>
<p><span class="math display">\[\begin{align*}
&amp; R_{2}(\overline{X_{2}}, a_{1}, a_{2}) \\
&amp; \quad = \mathbb{E} \bigg[ Y^{*}(a_{1}, \underbrace{d_{2}^{opt} (X_{1}, a_{1}, X_{2})}_{ =: \, d_{2}^{opt}})
- Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \bigg] \\
&amp; \quad \overset{(a)}{=} \mathbb{1}(d_{2}^{opt} \neq a_{2}) \,\,
\mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2})
- Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right]  \\
&amp; \quad =  \mathbb{1}(d_{2}^{opt} \neq a_{2}) \,\,
\left\{ \mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right]
- \mathbb{E} \left[ Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right]
\right\} \\
&amp; \quad =  \mathbb{1}(d_{2}^{opt} \neq a_{2}) \,\,
\bigg\{ \mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \hspace{3.2cm} + \mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-a_{2} \right] \mathbb{P} \left(A_{2} = 1-a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2}\right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2}\right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1 - a_{2} \right] \mathbb{P} \left(A_{2} = 1-a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right) \bigg\} \\
&amp; \quad \overset{(b)}{=} \mathbb{1}(d_{2}^{opt} \neq a_{2}) \,\,
\bigg\{ \mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \hspace{3.2cm} + \mathbb{E} \left[ Y \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-a_{2} \right] \mathbb{P} \left(A_{2} = 1-a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2}\right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2}\right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1 - a_{2} \right] \mathbb{P} \left(A_{2} = 1-a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right) \bigg\} \\
&amp; \quad = \mathbb{1}(d_{2}^{opt} \neq a_{2}) \,\,
\bigg\{ C + \mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1 - a_{2} \right] \mathbb{P} \left(A_{2} = 1-a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right) \bigg\}. \\
&amp; \hspace{1cm}  \text{ where } \,\, C := \, \mathbb{E} \left[ Y \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-a_{2} \right] \mathbb{P} \left(A_{2} = 1-a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2}\right) \\
&amp; \hspace{2.8cm} - \mathbb{E} \left[ Y \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2}\right). \\
\end{align*}\]</span></p>
<p>Here, <span class="math inline">\((a)\)</span> uses the fact that <span class="math inline">\(R_{2}=0\)</span> if <span class="math inline">\(d_{2}^{opt}=a_{2}\)</span>, and <span class="math inline">\(R_{2}&gt;0\)</span> if <span class="math inline">\(d_{2}^{opt} \neq a_{2}\)</span>, and <span class="math inline">\((b)\)</span> uses consistency assumption. Let <span class="math inline">\(p_{2} := \mathbb{P} \left(A_{2} = a_{2} \, | \, X_{1}, A_{1} = a_{1}, X_{2} \right)\)</span>. Since <span class="math inline">\(R_{2}\)</span> takes its maximum value when <span class="math inline">\(\mathbb{E} \left[ Y^{*}(a_{1}, 1-a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = a_{2} \right] = Y_{U}\)</span> and its minimum value when <span class="math inline">\(\mathbb{E} \left[ Y^{*}(a_{1}, a_{2}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1 - a_{2} \right] = Y_{L}\)</span>,</p>
<p><span class="math display">\[\begin{align*}
&amp; R_{2} \, \in \, \left[ \max(0 \,, \, C + \, p_{2} \times Y_{L} - (1- p_{2}) \times Y_{U}) \, , \,
C + \, p_{2} \times Y_{U} - (1- p_{2}) \times Y_{L} \right] \\
\Rightarrow \quad &amp; R_{2} \, \in \, \left[ \max(0 \,, \, C - Y_{U} + (Y_{L} + Y_{U}) \times p_{2})  \, , \, C - Y_{L} + (Y_{L} + Y_{U}) \times p_{2} \right]. \\
\end{align*}\]</span></p>
<p>Therefore, <span class="math inline">\(\left[ \max(0 \,, \, C - Y_{U} + (Y_{L} + Y_{U}) \times p_{2}) \, , \, C - Y_{L} + (Y_{L} + Y_{U}) \times p_{2} \right]\)</span> is the possible range of values in the regret at time <span class="math inline">\(2\)</span> in the presence of unmeasured confounder.</p>
</div>
<div id="regret-at-first-stage" class="section level4">
<h4>Regret at first stage</h4>
<p><span class="math display">\[\begin{align*}
&amp; R_{1}(X_{1}, a_{1}) \\
&amp; \quad = \mathbb{E} \bigg[ Y^{*}( \underbrace{d^{opt}_{1}(X_{1})}_{=:d^{opt}_{1}}, d_{2}^{opt}(X_{1}, d^{opt}_{1}, X^{*}_{2}(d^{opt}_{1}))) - Y^{*}(a_{1}, d_{2}^{opt}(X_{1}, a_{1}, X^{*}_{2}(a_{1}))) \, \bigg| \, X_{1} \bigg] \\
&amp; \quad  \overset{(a)}{=} \mathbb{1}(d_{1}^{opt} \neq a_{1}) \,\, \mathbb{E} \left[ Y^{*}( 1-a_{1}, \underbrace{d_{2}^{opt}(X_{1}, 1-a_{1}, X^{*}_{2}(1-a_{1}))}_{=: d^{opt}_{2}(1-a_{1})}) - Y^{*}(a_{1}, \underbrace{d_{2}^{opt}(X_{1}, a_{1}, X^{*}_{2}(a_{1}))}_{=: d^{opt}_{2}(a_{1})}) \, \bigg| \, X_{1} \right] \\
&amp; \quad  = \mathbb{1}(d_{1}^{opt} \neq a_{1}) \,\, \left\{ \mathbb{E} \bigg[ Y^{*}( 1-a_{1}, d^{opt}_{2}(1-a_{1}))  \, \bigg| \, X_{1}  \bigg] - \mathbb{E} \bigg[ Y^{*}(a_{1}, d^{opt}_{2}(a_{1})) \, \bigg| \, X_{1} \bigg] \right\} \\
&amp; \quad =  \mathbb{1}(d_{1}^{opt} \neq a_{1}) \,\,
\bigg\{ \mathbb{E} \left[ Y^{*}(1-a_{1}, d^{opt}_{2}(1-a_{1})) \, \bigg| \, X_{1}, A_{1} = a_{1} \right] \mathbb{P} \left(A_{1} = a_{1} \, | \, X_{1} \right) \\
&amp; \hspace{3.2cm} + \mathbb{E} \left[ Y^{*}(1-a_{1}, d^{opt}_{2}(1-a_{1})) \, \bigg| \, X_{1}, A_{1} = 1-a_{1} \right] \mathbb{P} \left(A_{1} = 1-a_{1} \, | \, X_{1} \right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y^{*}(a_{1}, d^{opt}_{2}(a_{1})) \, \bigg| \, X_{1}, A_{1} = a_{1} \right] \mathbb{P} \left(A_{1} = a_{1} \, | \, X_{1} \right) \\
&amp; \hspace{3.2cm} - \mathbb{E} \left[ Y^{*}(a_{1}, d^{opt}_{2}(a_{1})) \, \bigg| \, X_{1}, A_{1} = 1 - a_{1} \right] \mathbb{P} \left(A_{1} = 1 - a_{1} \, | \, X_{1} \right) \bigg\} \\
&amp; \quad =  \mathbb{1}(d_{1}^{opt} \neq a_{1}) \,\, \bigg\{
\mathbb{E}_{X_{2}} \left[ \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right]  \, \bigg| \, X_{1}, A_{1} = a_{1} \right]  \mathbb{P} \left(A_{1} = a_{1} \, | \, X_{1} \right) \\
&amp; \hspace{3.2cm} + \mathbb{E}_{X_{2}} \left[ \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  \, \bigg| \, X_{1}, A_{1} = 1 - a_{1}, X_{2} \right]  \, \bigg| \, X_{1}, A_{1} = 1 - a_{1} \right]  \mathbb{P} \left(A_{1} = 1 - a_{1} \, | \, X_{1} \right) \\
&amp; \hspace{3.2cm} - \mathbb{E}_{X_{2}} \left[ \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right]  \, \bigg| \, X_{1}, A_{1} = a_{1} \right]  \mathbb{P} \left(A_{1} = a_{1} \, | \, X_{1} \right) \\
&amp; \hspace{3.2cm} - \mathbb{E}_{X_{2}} \left[ \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  \, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2} \right]  \, \bigg| \, X_{1}, A_{1} = 1-a_{1} \right]  \mathbb{P} \left(A_{1} = 1-a_{1} \, | \, X_{1} \right) \bigg\}. \\
\end{align*}\]</span></p>
<p>where <span class="math inline">\((a)\)</span> uses the fact that <span class="math inline">\(R_{1}=0\)</span> if <span class="math inline">\(d_{1}^{opt}=a_{1}\)</span>, and <span class="math inline">\(R_{1}&gt;0\)</span> if <span class="math inline">\(d_{1}^{opt} \neq a_{1}\)</span>. Now, consider further expansion for conditional expectation on <span class="math inline">\(Y\)</span>.</p>
<p><span class="math display">\[\begin{align*}
  &amp; \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right] \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]  
\underbrace{\mathbb{P} \left(A_{2} = d_{2}^{opt}(a_{1}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right)}_{=: p_{1,a_{1}}} \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(a_{1})   \right]  
\mathbb{P} \left(A_{2} = 1-  d_{2}^{opt}(a_{1}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]  p_{1,a_{1}} \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(a_{1})   \right]  (1-p_{1,a_{1}}), \\
  &amp; \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  \, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2} \right] \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]  
\mathbb{P} \left(A_{2} = d_{2}^{opt}(1-a_{1}) \, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2} \right) \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(1-a_{1})   \right]  
\mathbb{P} \left(A_{2} = 1-  d_{2}^{opt}(1-a_{1}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]  
\underbrace{\mathbb{P} \left(A_{2} = d_{2}^{opt}(1-a_{1}) \, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2} \right)}_{=: p_{1,1-a_{1}}} \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(1-a_{1})   \right]  
\mathbb{P} \left(A_{2} = 1-  d_{2}^{opt}(1-a_{1}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]  p_{1,1-a_{1}} \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(1-a_{1})   \right]  (1-p_{1,1-a_{1}}), \\
  &amp; \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right] \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]  
\mathbb{P} \left(A_{2} = d_{2}^{opt}(a_{1}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(a_{1})   \right]  
\mathbb{P} \left(A_{2} = 1- d_{2}^{opt}(a_{1}) \, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2} \right) \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]  
p_{1,a_{1}}  \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(a_{1})   \right]  
(1-p_{1,a_{1}}), \\
  &amp; \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  \, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2} \right] \\
&amp; \quad = \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1- a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]  
p_{1,1-a_{1}} \\
&amp; \quad + \mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(1-a_{1})   \right]  
(1-p_{1,1-a_{1}}).
\end{align*}\]</span></p>
<p>Finally, with <span class="math inline">\(p_{1} := \mathbb{P} \left(A_{1} = a_{1} \, | \, X_{1} \right)\)</span>, we have</p>
<p><span class="math display">\[\begin{align*}
&amp; R_{1}(X_{1}, a_{1}) \\
&amp; \quad = \mathbb{1}(d_{1}^{opt} \neq a_{1}) \,\, \times \\
&amp; \hspace{1.2cm} \bigg\{
(1-p_{1}) \cdot \mathbb{E} \left[ p_{1,1-a_{1}} \cdot
\mathbb{E} \left[ Y \bigg| X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \\
&amp; \hspace{2.0cm} -
p_{1} \cdot \mathbb{E} \left[ p_{1,a_{1}} \cdot
\mathbb{E} \left[ Y \bigg| X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{2cm} +
p_{1} \cdot \mathbb{E} \left[ p_{1,a_{1}} \cdot
\mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{2cm} +
p_{1} \cdot \mathbb{E} \left[ (1-p_{1,a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(a_{1})   \right]
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{2cm} -
p_{1} \cdot \mathbb{E} \left[ (1-p_{1,a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(a_{1})   \right]  
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{1cm} +
(1-p_{1}) \cdot \mathbb{E} \left[ (1-p_{1,1-a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(1-a_{1})   \right]
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \\
&amp; \hspace{1cm} -
(1-p_{1}) \cdot \mathbb{E} \left[ p_{1,1-a_{1}} \cdot
\mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1- a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]  
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \\
&amp; \hspace{1cm} -
(1-p_{1}) \cdot \mathbb{E} \left[ (1-p_{1,1-a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(1-a_{1})   \right]  
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \bigg\}. \\
  &amp; \quad = \mathbb{1}(d_{1}^{opt} \neq a_{1}) \,\, \times \\
&amp; \hspace{1.2cm} \bigg\{ D +
p_{1} \cdot \mathbb{E} \left[ p_{1,a_{1}} \cdot
\mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1})   \right]
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{2cm} +
p_{1} \cdot \mathbb{E} \left[ (1-p_{1,a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(a_{1})   \right]
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{2cm} -
p_{1} \cdot \mathbb{E} \left[ (1-p_{1,a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(a_{1})   \right]  
\bigg| X_{1}, A_{1} = a_{1}  \right]  \\
&amp; \hspace{1cm} +
(1-p_{1}) \cdot \mathbb{E} \left[ (1-p_{1,1-a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(1-a_{1}, d_{2}^{opt}(1-a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1-d_{2}^{opt}(1-a_{1})   \right]
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \\
&amp; \hspace{1cm} -
(1-p_{1}) \cdot \mathbb{E} \left[ p_{1,1-a_{1}} \cdot
\mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1- a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1})   \right]  
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \\
&amp; \hspace{1cm} -
(1-p_{1}) \cdot \mathbb{E} \left[ (1-p_{1,1-a_{1}}) \cdot
\mathbb{E}_{Y} \left[ Y^{*}(a_{1}, d_{2}^{opt}(a_{1}))  
\, \bigg| \, X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = 1- d_{2}^{opt}(1-a_{1})   \right]  
\bigg| X_{1}, A_{1} = 1-a_{1}  \right] \bigg\}. \\
\end{align*}\]</span></p>
<p>where <span class="math inline">\(D := (1-p_{1}) \cdot \mathbb{E} \left[ p_{1,1-a_{1}} \cdot \mathbb{E} \left[ Y \bigg| X_{1}, A_{1} = 1-a_{1}, X_{2}, A_{2} = d_{2}^{opt}(1-a_{1}) \right] \bigg| X_{1}, A_{1} = 1-a_{1} \right] - p_{1} \cdot \mathbb{E} \left[ p_{1,a_{1}} \cdot \mathbb{E} \left[ Y \bigg| X_{1}, A_{1} = a_{1}, X_{2}, A_{2} = d_{2}^{opt}(a_{1}) \right] \bigg| X_{1}, A_{1} = a_{1} \right]\)</span>.</p>
<p>Therefore, <span class="math inline">\(R_{1} \in \left[ \max(0 \,, \, D + (Y_{L} - Y_{U}) + p_{1} \cdot p_{1, a_{1}} \cdot Y_{U} + (1-p_{1}) \cdot p_{1, 1-a_{1}} \cdot Y_{L} ) \, , \, D + (Y_{U} - Y_{L}) + p_{1} \cdot p_{1, a_{1}} \cdot Y_{L} - (1-p_{1}) \cdot p_{1, 1-a_{1}} \cdot Y_{U} \right]\)</span> is the possible range of values in the regret at time <span class="math inline">\(1\)</span> in the presence of unmeasured confounder.</p>
<hr />
</div>
</div>
<div id="summary" class="section level3">
<h3>Summary</h3>
<p>In summary, we reviewed a paper <em>Q- and A-learning Methods for Estimating Optimal Dynamic Treatment Regimes</em>, focusing on Q-learning methods. The goal of the paper is to make a series of optimal treatment decisions to achieve the best outcome for an individual patient, called a <em>dynamic treatment regime</em>. To estimate the optimal treatment regime, the Q-learning method uses recursive algorithms: we decide to maximize the expected potential <em>final</em> outcome and then decide on a previous stage under the subsequent optimal rules in a backward induction manner up to the first stage. Q-learning is based on “Q-functions” to estimate the expected potential outcome of a series of treatments which measures the ‘quality’ associated with the treatment. Then estimation of the optimal treatment rule is accomplished via direct modeling of Q-functions such as ordinary least squares.</p>
<p>Throughout the project, we identified the expected potential outcome as a statistical estimand, a function of conditional expectation, and estimated the quantity under Q-functions and inverse probability weighting. From the simulation study, the estimated treatment rule showed 95% prediction accuracy. However, the Q-learning approach yields a poor estimation of true parameters which affect decision rules due to misspecified Q-functions. As can be seen in the simulation study, the performance of the Q-learning approach is affected by model specification, which may result in poor estimation.</p>
<p>One possible approach to overcome the model specification issue is to use a robust approach that may not need any model assumption based on non-parametric inference. More specifically, we may use distance measures between the identified empirical distribution of the covariates and the weighted empirical distribution of covariates with inverse probability weighting of certain treatment groups. Without any further model assumption, we can find a weighting function that directly minimizes the distance between them.</p>
<p>This project is expected to contribute to understanding dynamic treatment regimes in the Q-learning framework. Anyone interested in how to identify and estimate causal estimands in longitudinal settings may find this helpful.</p>
<hr />
</div>
<div id="reference" class="section level3">
<h3>Reference</h3>
<p><a href="https://amy-cochran.gitbook.io/causal-inference/introduction/start-here">Causal inference lecture notes</a></p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/25620840/">Schulte, P. J., Tsiatis, A. A., Laber, E. B., &amp; Davidian, M. (2014). Q-and A-learning methods for estimating optimal dynamic treatment regimes. Statistical science: a review journal of the Institute of Mathematical Statistics, 29(4), 640.</a></p>
<p><a href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/2021/03/ciwhatif_hernanrobins_30mar21.pdf">Hernán, M. A., &amp; Robins, J. M. (2010). Causal Inference: What if. Boca Raton: Chapman &amp; Hall/CRC.</a></p>
<p><a href="https://rss.onlinelibrary.wiley.com/doi/epdf/10.1111/1467-9868.00389">Murphy, S. A. (2003). Optimal dynamic treatment regimes. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 65(2), 331-355.</a></p>
</div>
